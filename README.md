# BetPredictionProject



âš½ Pro Jupiler Pro League Football Match Prediction

## ğŸš€ Project Overview

ğŸ¯ **Objective:** This project aims to deliver highly accurate and insightful match predictions.
ğŸ“Š **Data Source:** https://www.football-data.co.uk/notes.txt
ğŸ”§ **Techniques Used:**
- Data collecting 
- Data Cleaning
- Feature Encoding
- Imputation of Missing Values
- Model Training & Evaluation
- Deployement with streamlit on Render

1. **Data Preparation**

    - ğŸ” **Data Collection:** Data Collection: Gathered and pre-processed historical match data from the Pro Jupiler            League, including scores, team lineups, and match events.
    - ğŸ§¹ **Data Cleaning:** Dropped irrelevant columns and handled missing values.
    - ğŸ·ï¸ **Feature Encoding:** Transformed categorical variables using OneHotEncoder.
    - ğŸ”„ **Imputation:** Applied KNN Imputation to handle missing values.

![Data Preparation](https://media.giphy.com/media/iFwgAGLxwHevR1ppM7/giphy.gif)

2. **Model Training**
   - ğŸ› ï¸ Feature Engineering: Developed various features such as team form, head-to-head statistics, player injuries, and other factors influencing match outcomes.
   - ğŸ“ˆ Machine Learning Models: Implemented and compared several machine learning models, including Logistic Regression, Random Forest, Gradient Boosting, to predict match results. 
   - ğŸ” Performed Grid Search to optimize hyperparameters.

![Model Trainin](https://media.giphy.com/media/qcsGTXHP8JkxaAa0cE/giphy.gif)

3. **Model Evaluation**
   - ğŸ§‘ğŸ’»Assessed the performance of each model using accuracy, precision, recall, F1 score, and AUC-ROC curves to select the best-performing model.
   - ğŸ¯ Fine-tuned the model based on evaluation results.

   ![Model Evaluation](https://media.giphy.com/media/vSGzVywEkoS6QCzfWN/giphy.gif)

4. **Prediction Interface**
    ğŸ’»:Built a user-friendly interface where users can input upcoming match details and receive predictions.

5. **Project Structure**

    ğŸ“‚ Pro Jupiler League-prediction
â”œâ”€â”€ ğŸ“ data
â”‚   â”œâ”€â”€ ğŸ“‚ raw               ## Raw data straight from the sources
â”‚   â”œâ”€â”€ ğŸ“‚ processed         ## Cleaned and ready-to-use data
â”‚   â””â”€â”€ ğŸ“‚ features          ## Engineered features for modeling
â”œâ”€â”€ ğŸ“ notebooks             # Jupyter notebooks for EDA and model experiments
â”œâ”€â”€ ğŸ“ models                # Trained and saved models
â”œâ”€â”€ ğŸ“ src
â”‚   â”œâ”€â”€ ğŸ“‚ data_processing   # Scripts for data cleaning and feature extraction
â”‚   â”œâ”€â”€ ğŸ“‚ modeling          # Scripts for model training and evaluation
â”‚   â”œâ”€â”€ ğŸ“‚ prediction        # Prediction generation scripts
â”‚   â””â”€â”€ ğŸ“‚ app               # Source code for the web application
â”œâ”€â”€ ğŸ“ tests                 # Unit tests to ensure robustness
â”œâ”€â”€ ğŸ“ README.md             # Project documentation
â””â”€â”€ ğŸ“„ requirements.txt      # Python dependencies


5. **Deployement with streamlit on Render**

   ğŸŒ Deployment: Deployed the final model as a web application for easy access and usage.

   ğŸ”— Deployment with Streamlit on Render

    To deploy the model using Streamlit on Render, follow these steps:

    âš™ï¸ Set Up Streamlit App: Create a streamlit_app.py file in the project directory. This file should include the code to load the model and present the prediction interface.

    âœ… Create a requirements.txt for Deployment: List all required packages for the Streamlit app. Include packages like streamlit, catboost, and any other dependencies.

    ğŸ“‚ Deploy on Render: Go to Render and create a new Web Service. Connect your GitHub repository and select the streamlit_app.py file. Configure the build and start commands (e.g., streamlit run streamlit_app.py).

    ğŸ§± Test Your Deployment: Once deployed, test the Streamlit app to ensure it functions correctly and provides accurate predictions.

    


## â³ Usage


Select the teams for the upcoming match.
Input additional factors such as injuries or suspensions.
Generate predictions for the match outcome and potential scoreline.

## ğŸ“Š Model Performance
The chosen model, Gradient Boosting Classifier, achieved the best performance with the following metrics:

Accuracy: 
Precision: 
Recall: 
F1 Score: 


## ğŸ“ˆ Visualization
